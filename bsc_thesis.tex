%!TeX spellcheck = de_DE
%\documentclass[a4paper,cleardoubleempty,BCOR1cm]{scrbook}
\documentclass[a4paper,cleardoubleempty,BCOR1cm]{book}

\input{header}

\usepackage[main=ngerman]{babel}

\pagenumbering{roman}
\title{Thesis Template}
\author{Tolga Demir \thanks{e-mail: tolga.demir@student.uni-tuebingen.de}}
\date{\today}
\begin{document}

\input{teaser}
\chapter*{Abstract}




\chapter*{Acknowledgments}
Mein Dank gilt Prof. Zell, der diese Bachelorarbeit engagiert begleitet und ermöglicht hat. \\
Weiterhin möchte ich mich herzlich beim Wohnheim Rechberghaus bedanken für die Bereitstellung einer Werkstatt. Ohne diese Hilfe wären mir manche Arbeiten am Roboter kaum möglich gewesen. 

\tableofcontents

\clearpage
\pagenumbering{arabic}

\chapter{Einführung}

% ganze Kapitel 5 Seiten max
\section{Autonome Mobile Roboter}
Mobile Roboter werden für eine breite Bandbreite an Arbeiten eingesetzt, darunter die Erkundung von menschenfeindlichen Umgebungen, das Verrichten von Arbeiten in diesen oder als Service-Roboter z.B. zum Rasenmähen oder Staubsaugen.\\
Die Bezeichnung autonom meint hierbei, dass die Roboter ihre Aufgaben (fast-) selbstständig erledigen. Dazu gehören neben der reinen Tätigkeit auch Themen wie das Fahren, Erfassen von Zielen, Erstellen von Karten ihrer Umgebung und zurecht finden in unbekanntem Terrain. \\
Mobile Roboter sind seit den 1960ern ein Feld intensiver Forschung mit vielen Applikationen in der Industrie. Seit den 2000ern werden eine Vielzahl von verschiedenen Mobilen Robotern für die Industrie verkauft. Diese frühen Generationen von Robotern sind aus heutiger Sicht überholt. Oft lässt sich weder die Hardware noch die Software für moderne Anforderungen konfigurieren.\\
Eine Kernfrage dieser Arbeit ist, ob sich ein solcher Roboter, exakter: der Ct'Bot des Heise Verlags aus dem Jahr 2006 mit minimalem Aufwand in Kosten und Umbau so neu gestalten lässt, dass er diesen Herausforderungen gewachsen ist. \\
Dies würde die Wiederverwertbarkeit älterer Roboter ermöglichen und so einen erheblichen Beitrag zu Kostensenkung und Umweltschutz garantieren, welche mit einer Neuanschaffung nicht zu realisieren wären. 

\section{Ziel dieser Arbeit}
Diese Bachelor-Arbeit widmet sich der Erneuerung des Ct'Bots. Dieser soll von Grund auf modernisiert und fit gemacht werden für die Anforderung neuerer Algorithmen und Datenschnittstellen. Der Roboter soll dabei nicht an Größe gewinnen und seine Vorteile weiterhin behalten. \\

Zugleich wird ein Python Framework entwickelt, welches ein solides Gerüst für weitere Anwendungsentwicklungen darstellt. Es soll intuitiv und schnell einsetzbar sein und die komplette Funktionalität des Roboters bereitstellen. Hierdurch wird dem Roboter ein neuer Einsatzzweck ermöglicht. \\


\section{Methodik und Beschränkungen}

Durch Analyse der vorhandenen Hardware sollen Lücken im Funktionsumfang ausgebessert und der Roboter befähigt werden, eine moderne SLAM-Implementation (Simultainous Self-Lokalization and Mapping) autonom auszuführen. 
Dabei müssen die beschränkte Genauigkeit kostengünstiger Sensorik beachtet werden. Weiterhin soll die Modernisierung ein Budget von 100Euro für neue Hardware nicht übersteigen. 

\section{Gliederung und Aufbau}

Diese Arbeit erörtert im Folgenden die Grundlagen der Mobilen Robotik Hardware und- eingeschränkt- das Thema SLAM. Danach wird ausführlich über die vorhandene Hardware und die Erneuerung des Roboters berichtet. Für den fertigen Roboter wird dann ein Software-Framework vorgestellt, welches eine Plattform für die komplette Funktionalität darstellt. \\
Abschließend werden verschiedene  Tests des Prototypen präsentiert und die Ergebnisse erörtert. \\
Mit einer Zusammenfassung der Arbeit und einen Ausblick endet diese Dokumentation.  





% ganze Kapitel 5 Seiten max
\chapter{Grundlagen}
In diesem Kapitel werden die Grundlagen, welche zum Verständnis dieser Arbeit benötigt werden kurz erläutert.

\section{Hardware Mobiler Roboter}
Ein Mobiler Roboter besteht aus mindestens einer Hauptplatine für die Steuerung, einer Möglichkeit der Fortbewegung und einer Energie-Quelle. \\


\section{Mobile Hardware und ihre Lebenszeit}
Gordon Moore behauptete 1965, dass sich die Komplexität von Integrierten Schaltkreisen alle zwei Jahre verdoppeln würde \footnote{ G. E. Moore: Cramming more components onto integrated circuits. In: Electronics. Band 38, Nr. 8, 1965, S. 114–117}. Diese Aussage wurde bekannt als das Mooresche Gesetz und hält sich bis heute. Die Konsequenz daraus ist, dass jeder neu entwickelte Chip innerhalb weniger Jahre als Leistungsschwach gilt und nicht mehr dem Stand der Technik entspricht. Eine derart radikale und dauerhafte Erneuerung kennt sonst kein Industrieprodukt. Diese schnelllebige Entwicklung setzt sich vom Chip fort auf die fertigen Systeme. Insbesondere Mobile Roboter erleben mit jeder weiteren Generation einen enormen Leistungsschub. Durch die Knappheit von Ressourcen die eine Mobile Hardware mit sich bringt fällt jede weitere technische Innovation schwerer ins Gewicht. Sinkt zum Beispiel der Stromverbrauch des Hauptprozessors, so steigt als Folge die Laufzeit des akku-betriebenen Mobilen Roboters, während dieser Aspekt bei standort-gebundener Hardware kaum Nutzen bringt. Sinkt das Gewicht und die Größe von Sensorbauteilen so wirkt sich das ebenso erheblich auf Erscheinung, Funktionsumfang und -dauer des Mobilen Roboters aus. Welche Auswirkungen diese Entwicklungen hat lässt sich sehr anschaulich am Roboterhersteller Boston Dynamics beobachten. Ihr 4-Beiniger Roboter BigDog wurde 2009 vorgestellt und sollte ein Mobiler Roboter zum Transport von schweren Gewichten in Wald- und Landwirtschaftsgebieten sein. Es war ihm dabei schon möglich seine Balance - auch gegen Widerstand - zu halten und geführte Wege abzuschreiten. Vergleicht man ihn jedoch mit dem 2017 vorgestellten SpotMini, so erkennt man den enormen Sprung der Technik. So erreicht der neue SpotMini Laufgeschwindigkeiten von über 100 Km/H und hat eine Last-Laufzeit welche ein Vielfaches seines Vorgängers ist. \\
Die Konsequenz dieser Erkenntnis wäre, Hardware und jede Chip-gebundene Technik im 2-3 Jahres-Rythmus zu tauschen. Betrachtet man bei dieser Überlegung jedoch die Wirtschaftlichen und Umweltpolitischen Aspekte, so scheint das kontraproduktiv. Moderne Roboter können Preise bis weit über einen 6-stelligen Euro Betrag kosten (z.B betragen die reinen Produktions- und Entwicklungskosten des Atlas2 1 Mio Dollar pro Stück). Versucht man nun seine Wirtschaftlichkeit auf einer Einsatzdauer von 2 Jahren zu brechnen, so muss das Resultat negativ ausfallen. \\
Gerade in Unternehmen, wird Hardware daher oft so lange wie möglich genutzt. Zumindest solange eine Möglichkeit besteht diese an die geforderten Arbeitsprozesse anzupassen. \\

Innerhalb der Sensorik-Komponenten ist die Entwicklung ähnlich gelagert - wenn auch die Erneuerung nicht so schnell wie im Chip-Bereich ausfällt. Insbesondere sind viele Sensoren früh in ihrer heute üblichen Form auf den Markt gekommen. Das zeigt z.B. der Reflexoptokopter wie er auch in unserem Roboter verbaut ist. Der CNY70 ist in seiner jetzigen Bauform schon seit 2001 auf dem Markt. Seitdem hat sich zwar der preis radikal reduziert (von einem hochklassigen Sensor zu einem 1Cent Produkt), jedoch nicht seine Einsatzgebiete. Reine Sensor-Produkte sind somit mehr von ihrer internen Laufzeit abhängig als von der Entwicklung des Marktes. Da sie sehr häufig für einen spezifischen Zweck gebraucht werden und keine frei programmierbaren Teile sind. 


\section{Software Mobile Roboter}
Moderne Mobile Roboter haben meist ein eigenes Betriebssystem, welches ihre Funktionen im Ganzen steuert und dem Anwender die Funktionalität als (modulares-) Framework bereitstellt. Dies erlaubt es Roboter, welche unterschiedlichste Hardware und Sensorik haben, schnell und einfach zu kontrollieren. Hierbei ist vor allem das Robot Operating System (ROS) in der Forschung weit verbreitet. ROS arbeitet mit einem Baukasten-Prinzip, welches über Knoten die Anbindung von Sensoren und ihren Daten an einen Roboter erlaubt. Roboterhersteller entwickeln hierauf aufbauend eigene Betriebssysteme oder Frameworks. So nutz reines ROS z.B. ABB. Während KUKA ihr selbst entwickeltes KRL einsetzt. Ebenso Fanuc mit Karel. \\
ROS, als open-source Projekt, wird von den Nutzern ständig weiterentwickelt und um Funktionalitäten erweitert. So sind komplexeste Algorithmen und Sensorsteuerungen direkt im System vorhanden und müssen nicht jedes Mal neu gedacht werden. Dies ist als seine größte Stärke zu betrachten. Von Nachteil ist die Komplexität des Systems. Die vorhandenen Möglichkeiten zur Sensoranbindung und Algorithmen-Steuerung machen ROS unübersichtlich und führen zu vielen Fehlern bei weniger geüübten Nutzern. Weiterhin ist ROS ein großes System. Viele ältere Roboter und schwächere Hauptprozessoren sind nicht in der Lage ROS als Ganzes zu hosten. Zudem kann ROS Die Kanone sein, mit der auf Spatzen geschossen wird. Nicht jeder Mobile Roboter braucht das vollständige ROS, oft sind diese mit einem kleinen, für sie geschriebenen System schneller und zuverlässiger. \\
Als Alternativen für kleinere Systeme haben sich Rasbian, Embedded Linux oder Windows CE etabliert. Die Wahl hängt hier vom Hauptprozessor oder der Steuerungseinheit ab. So eignet sich der Rasbian dann, wenn der Mobile Roboter von einer Raspberry Pi gesteuert wird. Während Arduino eine einfache Möglichkeit ist C Code auf einem gleichnamigen Chipset zu implementieren. Windows CE ist eine verschlankte Windows-Variante und sollte zu Beginn ein Betriebsystem für Mobilen Roboter darstellen. Es entwickelte sich aber eher in Richtung Mobile Telefone und Konsumenten-Endgeräte und wird daher kaum noch im Roboter bereich genutzt. \\
Zu diesen Betriebssystemen gibt es noch weitere, spezialisierte Echt-Zeit-Betriebssysteme wie RTLinux oder VxWorks. Diese werden für die Controlle und Vernetzung einzelner Hardware-Komponenten genutzt. Seltener als Framework oder Betriebssystem für einen kompletten Roboter. \\

Die wichtigsten Eigenschaften eines Roboter-Frameworks sind somit :
\begin{itemize}
	\item Wenig Speicherverbrauch:\\
			Durch die Begrenzung des Speicherplatzes vieler Mobiler Roboter ist ein kleines Betriebssystem zu bevorzugen. 
	\item Schnelligkeit und Möglichkeit der Echt-Zeit-Datenverarbeitung: \\
			Hier müssen insbesondere Sensorik-Messdaten direkt ausgelesen und verarbeitet werden können. Dies muss schnell passieren. So braucht z.B. ein klassischer Ultraschall-Sensor für den Betrieb mind. eine Verbindung zum Verarbeitenden System, welche in Schallgeschwindigkeit die Messdaten ablesen kann. 
	\item Geringer Energieverbrauch:\\
			Im Bereich der Mobilen Roboter dient der Akku als Hauptstromquelle. Dieser begrenzt die Laufzeit des Systems. Umso weniger der Roboter im Ruhezustand verbraucht umso länger kann er agieren. 
	\item Möglichkeit der Sensor-Angliederung:\\
			Das Betriebsystem muss befähigt sein Sensoren anzusprechen und Daten von diesen Empfangen zu können.
\end{itemize}

Klassische Merkmale moderner Betriebssysteme, wie ein User-Interface, Daten-Manager oder Ausführbarkeit von 3D-Visualisierungen sind in der Robotik kein Thema. 

\section{SLAM - Simultainous Self-Lokalization and Mapping }
Die Grundlage der jeder Interaktion mit seiner Umwelt stellt beim Mobilen Roboter seine Karte dar. Der Roboter bewegt sich innerhalb seiner Umwelt und muss dabei jederzeit wissen wo er sich befindet und wie er zu einem Bezugspunkt ausgerichtet ist. \\
Mit Hilfe seiner Karte und seiner Ausrichtung kann nun der Roboter sich in seiner Umwelt bewegen, bestimmte Ziele ansteuern und Aufgaben erledigen. Startet der Roboter in einem unbekannten Umfeld, so muss er diese Karte selbstständig generieren. Dieser Prozess wird als SLAM bezeichnet. Dabei erkundet der Roboter den Raum, erfasst die wichtigsten Umwelt-Daten und hält seine veränderte Position zu jedem Zeitpunkt fest. \\
Dies wird häufig als Henne-Ei-Problem bezeichnet, da der Roboter weder die Umgebung kennt noch seine Position in dieser und trotzdem beide Parameter schätzend berechnen muss. \\
Ermöglicht wird ein SLAM- Algorithmus durch die Sensorik des Roboters. Dazu braucht er -meist - zwei Dinge: 
\begin{enumerate}
	\item Odometrie:\\
	 Er muss jede Änderung seiner Position und Ausrichtung exakt messen können. Kann er dies nicht, so verliert er seine Position im Verhältnis zum Ausgangspunkt und die Karte kann nicht mehr korrekt berechnet werden. Dies nennt man Odometrie. In den frühen Jahren wurden hierfür Radsensoren eingesetzt. Diese sollten jede Bewegung des Roboterrads messen und damit Rückschlüsse auf gefahrene Strecke und Ausrichtung erlauben. Dies lässt sich einfach implementieren, gilt jedoch aufgrund von "wheel slips" (Radbewegungen ohne Bewegungen des Roboters oder Bewegung des Roboters ohne Bewegung der Räder) als sehr ungenau. \\
	 Eine weitere Möglichkeit stellen Optical-Flow-Sensoren dar. Diese nehmen aus kürzester Distanz Bilder des Bodens auf. Jede Bewegung des Roboters resultiert nun in einer Verschiebung innerhalb des Bildes. Diese kann berechnet werden und gibt die Veränderung zwischen jeder Bewegung exakt wieder. Optical-Flow-Sensoren werden z.B. in Computer-Mäusen eingesetzt. In der Robotik sind Sie eine Nische, da ihre Nachteile (Sensor muss nah am Boden verbaut sein, Untergrund muss glatt und sauber sein) überwiegen. \\
	 Odometrie Daten können auch über Kameras gewonnen werden. Diese funktionieren wie ein Opti-Flow-Sensor auf einem hoch-frequentierten Vergleich der Bilder miteinander. \\
	 Ebenso eignen sich hierzu Lidar-Sensoren. Diese werden in neuesten Robotern standartmäßig genutzt. Ihre Messungen sind die Exaktesten, jedoch brauchen Sie komplexere Algorithmen und - ihr größter Nachteil - sind vergleichsweise teuer. Dafür erlauben Sie, ebenso wie manche Kameras, die implementierung von Algorithmen, welche Odometrie und Distanzmessung vereinigen. 
	\item Sensorik um Distanzen zu messen. Bewegt sich der Roboter, muss er erkennen wo Hindernisse sind. Dies wird durch Distanz-Sensoren erreicht. Der Roboter misst nach jeder Bewegung die Abstände um ihn herum und kann so erkennen wie die Karte zu gestalten ist. 
\end{enumerate}

Mit diesen gewohnnen Daten kann der SLAM-Algorithmus eine Karte entwickeln. Algorithmen wie der Kalman-Filter vereinigen dabei beide Punkte - Odometrie und Distanzmessung- in Einem. Viel genutze Methoden sind beispielhaft PartikelFilter, Kalman-Filter oder Graphen-basierte SLAMs. Alle Algorithmen haben dabei besondere Voraussetzungen an die genutzte Sensorik und die Genauigkeit der Daten. 


\section{Zusammenfassung}
Hard- und Software bilden gemeinsam den Kern dieser Arbeit. Wie veranschaulicht wurde, braucht der Ct'Bot für versch. Aufgabenstellungen eine Möglichkeit sich in der Welt zurecht zu finden und sich ein Bild von dieser machen zu können. Im folgenden Kapitel soll mit Hilfe dieses theoretischen Wissens der vorhandene Roboter analysiert werden und jede seiner Komponenten auf Funktionsfähigkeit untersucht werden. \\
Danach wird die Software betrachtet und Entscheidungen bezüglich Umfang und Auswahlkriterien getroffen. 









% ganze Kapitel 10 Seiten max
\chapter{Ct'Bot}
Der Ct'Bot wurde 2006 von der Zeitschrift Ct' des Heise Verlags herausgebracht. Er kostete in der Basisversion ab 250Euro und kam als Baukasten. Die Bauteile wurden halb-fertig geliefert. Der Kunde musste versch. Bauteile auf die Platinen löten und das Ganze zusammenschrauben. \\
Der fertiggestellte Roboter ließ sich über ein mitgeliefertes Kabel an den PC anschließen und programmieren. Kern der Software bildete ein offenes Betriebssystem, welches extra für den CT'Bot geschrieben war. Die Kern-Software war dabei gestellt und wurde durch User ständig erweitert. So wuchs die Kern-Bibliothek an Funktionen mit der Anzahl der Nutzer. \\
Die Software selbst war in der Programmiersprache C gehalten und besaß weiterhin eine Simulationsumgebung, welche geschriebenen Code in einer virtuellen Welt testen konnte. \\
Leider ist das Projekt inzwischen eingestellt und wird nicht mehr vom Produzenten unterstützt. Es gibt keinen Zugriff mehr auf die Programmier-Bibliotheken und Ersatzteile können nicht mehr nachgekauft werden. Ebenso sind alle erschienen Artikel und das CT'Bot-Wikipedia verschwunden oder hinter Bezahlschranken. Das Projekt gilt als ausgestorben. \\
Der Ct'Bot dieser Arbeit wurde im Rahmen einer Doktor-Arbeit aufgebaut. Ziel war ein Multi-Slam-Algorithmus mit mehreren CT'Bots, welche von einem Controll-Tower geleitet wurden. Danach kam er nicht mehr zum Einsatz. 

\section{Erneuerung der Hardware}
In diesem Kapitel wird die vorhandene Hardware analysiert und Verbesserungspotenzial untersucht. Dabei wird abgewogen zwischen jetziger Leistungsfähigkeit und der Möglichkeit neuer Sensorik sowie dem Preis dieser. 

\subsection{Vorhandene Hardware}
Der Ct'Bot, welcher den Grundstein für diese Arbeit legt, sollte folgendermaßen aufgebaut sein:

\includegraphics[scale=0.1]{CBot_mod.jpg}

Die übergebene Hardware wurde auf Funktionsfähigkeit überprüft und zukünftige Einsatzfähigkeit analysiert. 

\subsubsection{Hauptplatine}
Die erste Generation des Ct'Bot wurde mit einem Atmel ATmega32 bestückt. Dieser konnte jedoch zu einem ATmega644 erweitert werden, wie es auch bei dem vorliegenden Ct'Bot der Fall ist. Der ATmega 644 arbeitet dabei mit 24 MHZ, 4kB Ram und 64kB Flash Speicher. Verbaut war der Hauptprozessor auf der mittleren Platine. Dieses wurde oft Mainboard genannt, da es die komplette Sensorik bündelte und die einzige, standartmäßig verbaute Platine war. 

\includegraphics[scale=0.1]{images/mainboard.jpg}

Die CPU war ausreichend um den Ct'Bot zu kontrollieren und einfache Aufgaben zu berechnen und auszuführen. Scheiterte jedoch an größeren Daten oder Karten wegen mangelnder Rechenleistung und Speicherplatz. 

\subsubsection{Wheel-Encoder und Cliff-Detektoren}
Als 'Lichtschranken' vermarktete CNY70 fungieren beim Ct-Bot als Wheel-Encoder und Cliff-Detektoren. Diese Sensoren können auf 1-2mm Distanz exakt hell-dunkel Übergänge auf einer Fläche erkennen. Dabei produzieren Sie ein analoges Ausgangssignal, welches Ansteigt auf dunklen Flächen und wieder abnimmt auf helleren. Diese Eigenschaft wird gepaart mit einer Kodierungsscheibe um die Radachse herum. Diese besteht aus eng beieinander liegenden Schwarz-Weiß-Balken. Richtet man den CNY70 danach aus, so erkennt er - bei Bewegung des Rads und der Kodierungsscheibe - die Wechsel. Diese nennt man Ticks. Ein guter Tick-Wert für ein Rad mit 3cm Durchmesser wären 200-300 Ticks. Der Ct'Bot hat 64. Diese werden mit dem CNY70 in der vorgegebenen Konstruktion kaum erreicht, da der Sensor sehr empfindlich auf Umgebungslicht reagiert und zu weit vom Rad entfernt sitzt. \\
Das gleiche Problem ergibt sich bei den Cliff-Detektoren. Das sind CNY70-Sensoren an der vorderen Roboterseite. Sie blicken Richtung Boden und sollen erkennen, wenn der Roboter sich über einem Abgrund befindet. In diesem Fall schalten sie ebenso ein analoges Output-Signal hoch. Leider waren die Sensoren zu hoch angebracht und lieferten daher fehlerhafte Werte. 

\subsubsection{Motor}
Der Ct'-Bot wird von 2 Faulhaber 2619 SR 006 DC-Motoren bewegt. Sie werden mit 5 V betreiben. 

\subsubsection{Distanzsensoren}
Als Distanzsensoren dienen zwei Infrarot-Distanzsensoren GP2D12 von Sharp. Diese haben einen Messbereich von 10-80cm und arbeiten mit Infrarot-Strahlen. Dies ermöglicht eine Punktgenaue Messung mit zuverlässigen Werten. Jedoch sind die Sensoren anfällig gegenüber Materialoberflächen. So können gemessene Daten stark voneinander abweichen, je nachdem auf welche Fläche sie treffen. Ebenso von Nachteil ist der hohe Stromverbrauch und die fehlende Abschirmung der Sensoren. Ihre Platine ist ungeschützt und frei liegen zur Rückseite. 

\subsubsection{Kompass}
Für die Messung der Ausrichtung wurde dem Ct'Bot nachträglich ein Kompass von Devantech installiert. Der CMPS03 hat eine Genauigkeit von 3-5 Grad und misst in Bezug zum Nordpol. Die exakte Kalibrierung des Kompass ist äußert mühsam und wurde von \cite{Hofmeister} in seiner Doktorarbeit beschrieben. Ebenso hatte dieser wiederholt Probleme mit der Genauigkeit der Messungen. 

\subsubsection{Optical-Flow Sensor}
Als weitere Odometrie-Sensor hat der Ct'Bot einen ADNS-2610 Optical-Flow-Sensor von Avago verbaut. Der Optical-Flow-Sensor ist im hinteren Teil des Roboters verbaut und in der normalen Version zu hoch angebracht, so dass er keine Werte liefert. Wird der Sensor tiefergelegt, so misst er den Fluss von Pixeln in schnell hintereinander aufgenommen Bildern und berechnet daraus eine Veränderung der Lage. Dies funktioniert mit einer Auflösung von 0,635 mm (400 Counts Per Inch, CPI) \footnote{Siehe hierzu Datenblatt des Sensors}. Somit sehr exakt. 

\subsubsection{LCD}
Es wurde zusätzlich ein DEM20485 LCD von Ryston verbaut. Leider war dieser nicht mehr ganz funktionstüchtig. So wurde die untere Reihe nicht klar dargestellt. 

\subsubsection{Kamera}
Der Ct'Bot verfügte über ein Kamera-Modul. Diese konnte Bilder in der Auflösung von ... erstellen. Leider ist der Speicherplatz des Ct'bot hierfür nicht ausreichend, daher musste eine zusätzliche SD-Karte eingebaut werden. Diese war ebenfalls nicht vom Ct'bot direkt lesbar. Er konnte nur Speicher- und Sendebefehle ausführen, jedoch nicht darstellen oder analysieren. 

\subsubsection{verschiedene Chips}
Ein zusätliches Wlan-Modul von Lantronic ermöglichte die Kommunikation versch. Ct'Bots miteinander. Die Funktionstüchtigkeit des Moduls konnte nicht überprüft werden. \\
Das SD-Karten-System ist ein selbstentwickeltes Modul und kann 512 Byte pro 5ms (also 0,5MB/sec, die Raspberry Pi 3 hat eine
durchschnittliche Schreibgeschw. von 20-50MB/s, abhängig von eingesetzter Karte) schreiben. Beim Schreiben und Lesen wird auf der Karte kein Fat32 Format verwendet, sondern ein selbstgeschriebenes Format genutzt. Dies verzichtet auf einen spezielles Dateisystem und nummeriert die Blöcke einfach durch. Diese werden nun von vorne beginnend geschrieben. Ein Zugriff beginnt daher auch immer am ersten Block und iteriert bis zur gesuchten Nummer durch die ganze Karte. Große Karten verzögern daher den Zugriff enorm. Ein praktischer Nutzen für moderne Systeme ist daher nicht mehr gegeben. 

\subsubsection{Grundplatte}
Eine Aluminium-Platte mit einem Durchmesser von 12 Zentimetern bildet die Grundplatte. Der ganze Ct'Bot ist so konzipiert, dass diese Grundplatte modular Erweitert werden kann. Jedes neue Modul wird hierbei auf die Grundplatte aufgeschraubt. Dadurch wächst der Roboter immer in die Höhe und behält seine Grundform bei. Immer dabei war die erste Ebene, das Mainboard. Alle weiteren Erweiterungen waren spezielle Zukaufteile oder selbstentwickelt. 

\subsubsection{Fehlende Bauteile}
Nicht mehr vorhanden waren das Batteriefach, ein PC-Kabel (9-Poliger D-Sub-Stecker, leider kein Anschluss an moderne Rechner möglich da dies ein überholtes Format ist), die Fernbedienung und der Ultraschall-Distanzssensor. 

\subsection{Neue Hardware}
In diesem Abschnitt wird die neue Hardware vorgestellt mit einer kurzen Begründung warum diese ausgewählt wurde. 

\subsubsection{Hauptplatine}
Der bisherige CPU wird für die künftigen Aufgaben nicht leistungsstark genug sein. Als Alternative würde sich erneut ein ATmega anbieten, wie z.B. der ATmega328P. Dieser ist auf dem Arduino Uno verbaut und kostet als Einplatinen-Computer 20Euro. Er bietet die Möglichkeit digitale und analoge Pins anzusteuern und hat eine ausreichend starke Rechenleistung. Jedoch ist hier, ebenso wie bisher, der Speicherplatz mit 32kB begrenzt. Für komplexere Projekte empfiehlt sich daher eine Raspberry Pi 3B. Mit einem Preis von ca. 35 Euro ist sie zwar teurer, erlaubt aber den Speicherplatz variable zu vergrößern. Zusätzlich ist sie - in Verbindung mit Raspbian - ein vollständiger Stand-alone-PC und erlaubt so die Verwirklichung von hochkomplexen Steuerungen oder Algorithmen. Ein weiterer Vorteil ist ihre kompakte Größe, ihre leichte Programmierbarkeit und der niedrige Stromverbrauch. \\
Die Pi hat den Nachteil, dass sie keine analogen Eingänge besitzt. Dies muss über einen  Analog-Digital-Konverter (ADC) kompensiert werden. \\
Weitere Möglichkeiten wären ein Asus Tinker Board, Banana Pi, BeagleBoard oder HumminBoard. Diese bieten meist gleiche bis etwas mehr Ausstattungsmerkmale als die Pi, kosten jedoch bis zu drei Mal soviel. 


\includegraphics[scale=0.25]{images/Pi.jpg}

Die Raspberry Pi 3B+ hat einen Broadcom Chip mit 1.4Ghz, 1GB SDRAM, eingebautes Wlan und Bluetooth, ein Ethernet-Stecker, 4 USB-Ports, einen Stecker für eine Kamera, HDMI-Ausgang, einen Micro-SD Steckplatz und 40 programmierbare Pins für digitale In- und Outputs. Sie wird mit 5V betrieben. \footnote{Daten aus dem Datenhandbuch, Bild von der Offiziellen Website}\\
Diese Spezifikationen sollten für unsere Software-Anforderungen ausreichen. 

\subsubsection{Kamera}
Die bisherige Kamera lässt sich nicht an die Pi anschließen. Daher wird Sie durch eine Raspberry-Pi Kamera ersetzt. Hierbei wird nicht die übliche Ausführung gewählt, sondern eine mit kontrollierbarem Infrarot-Filter. Durch diese Option ist es der Kamera möglich auch in völliger Dunkelheit Bilder aufzunehmen. Kameras für die Pi haben in der Regel eine Auflösung von 2592×1944 und einen manuell verstellbaren Fokus. Dies senkt die Kosten, muss aber bei der Einstellung mit bedacht werden.

\subsubsection{Akku}
Der Ct'Bot wurde von einem Akku-Pack betrieben, welcher aus zusammengeschlossenen AA-Baterien bestand. Hiervon waren 6 nötig. Dies begrenzte die Flexibilität und wird daher durch eine handelsübliche Powerbank ersetzt. Diese sollte mindestens 10.000mA haben um eine Laufzeit von 5-6 Stunden zu gewährleisten. Weiterhin ist darauf zu achten, dass sie über ein USB-Kabel angeschlossen werden kann. 

\subsubsection{Wheel-Encoder}
Die bisherigen Wheel-Encoder waren unzuverlässig. Sie wurden daher durch eine verbesserte Variante des CNY70 ersetzt. Die neuen Wheel-Encoder sind TCRT5000 Chips. Diese werden von vielen Herstellern zu geringen Preisen angeboten und ihr Messprinzip ist analog zum CNY70. Verbessert sind hierbei die Reaktion auf einen Input, hinzufügen eines digitalen Ausgangs, Distanz auf die gemessen werden kann und eine Regelbarkeit der Jump-Spannung. D.h. der benötigte Kontrast/Unterschied der Hell-Dunkel-Übergänge kann eingestellt werden. 

\subsubsection{Distanzsensoren}
Die GP2D12 werden heute noch in neuere Systeme verbaut. Es besteht kein Grund diese Auszutauschen. \\
Der Roboter wird jedoch um Ultraschall-Distanz-Sensoren erweitert. Diese sind günstig von vielen Herstellern zu bekommen und erlauben eine Abschätzung der Distanz auf 10-60 Zentimetern. Zu beachten ist, dass die Ultraschall-Distanz-Sensoren einen sehr breiten Streubereich haben. Während die Sharp-Sensoren punkgenau messen, misst dieser Sensor eine ganze Fläche ab und erhält dabei stets die kleinste gemessene Distanz.\\
Weiterhin problematisch ist bei Ultraschall, dass die Sensoren miteinander interferieren können. Dies tritt insbesondere dann zu tage, wenn der Roboter sich auf engstem Raum bewegt. Daher dienen diese Sensoren tatsächlich nur der Abschätzung und um die bisher unerfassten Bereiche links und rechts vom Roboter zu messen. 

\subsubsection{Gyroskop}
Die Ungenauigkeit des Kompasses macht es nötig einen Ersatz zu suchen um die Ausrichtung des Roboters zu messen. Hierfür bieten sich kostengünstige MPU6050 Sensoren an. Diese können Drehungen und Beschleunigungen an der x-,y- und z- Achse bestimmen. Ihre Genauigkeit beträgt dabei 1-2 Grad für die Drehung. Sie verfügen über ein I2C-Kommunikations-Interface und können darüber an die Pi angeschlossen werden. 

\subsubsection{LCD}
Es wird das LCD ausgetauscht gegen ein kompakteres 2 zeiliges Display. 


\subsubsection{Grundplatte}
Die alte Grundplatte ermöglichte leider nicht den Einbau der Pi und der Powerbank in liegender Position. Daher wurde die Grundplatte von 12 auf 15cm Durchmesser erhöht. Dadurch war auch ein verbesserter Einbau der Cliff-Sensoren und des Optical-Flow-Sensors möglich. 

\subsubsection{Sensorplatine}
Die Sensorplatte fasst alle Sensoren zusammen. Diese haben keinen Platz mehr auf dem Motherboard der Pi. Das alte Board konnte durch die Erweiterung nicht wiederverwendet werden. Daher wurde eine neue Sensorplatte entworfen und bildet nun die mittlere Schicht des Roboters. 


% ganze Kapitel 10 Seiten max
\section{Software-Framework}
Ein Software-Framework sollte die einfache Bereitstellung von Funktionen bieten. Das Roboter-Framework sollte so ermöglichen, dass ein Anwender die Treiber für die Sensorik nicht selbst schreiben muss, sondern sich die benötigten Daten vom Framework bereitstellen lässt. Dies erlaubt ein schnelleres Entwickeln von Anwendungen für den fertiggestellten Roboter. 

\subsection{Python}
Das entwickelte Framework nutzt als Sprache Python. Python ist ursprünglich eine reine objekt-orientierte Skriptsprache gewesen zum Ausführen kleiner Aufgaben und Funktionen. Mit Python 2 wurde die Funktionalität der Sprache selbst so erweitert, dass sie nun die gleichen Projekte realisieren kann, welche z.B. in Java geschrieben werden. \\
Python erlaubt schnelle, kleine Skript-Dateien miteinander zu kombinieren und ermöglicht damit größere Programme 'zusammen zu bauen'. Weiterhin lässt sich Python-Code auf allen Betriebssystemen direkt ausführen und muss nicht maschinen-bezogen programmiert werden. \\
Python gilt auch als natürliche Sprache der Pi. Diese erlaubt die gesamte Steuerung des Rechners über Python-Skripte. Daher gibt es innerhalb der Pi-Community im Internet eine große Datenbank fertiger Skripte, welche die Programmierzeit erheblich verkürzten, da nicht mehr jede Funktionalität selbst programmiert werden muss. \\
In diesem Projekt wird Python 2.7 verwendet, da dies hochskalierbar auf Python 3.x ist. Der Weg von 3 auf 2.7 jedoch nicht möglich ist. Damit wird die Funktionalität des Frameworks auch für ältere Pi Modelle gewahrt.

 
\subsection{PyBot- Framework}
Das PyBot-Framework wurde speziell für diesen Roboter entwickelt, lässt sich jedoch auf ähnliche Roboter umschreiben. \footnote{näheres im Anhang unter Installation}
Es ist eine Sammlung von Skripten, welche die Steuerung alle nötigen Sensorik übernimmt und als Funktionen und Klassen dem Nutzer zur Verfügung stellt. 


\subsection{Hardware Treiber}

\subsection{SLAM}



% ganze Kapitel 10 Seiten max
\section{Evaluierung}

\subsection{Testumgebung}

\subsection{Ergebnis}

\subsection{Diskussion und Bewertung}


\subsection{Zusammenfassung}




% 5 Seiten max
\chapter{Zusammenfassung und Ausblick}

\section{Zusammenfassung}

\section{Ausblick}



% ... input content via other .tex files
%\input{content/conclusion}

\appendix
\chapter{Anhang}
\section{Erklärung}
Im Anhang wird der Zusammenbau des Pybots erklärt. Neben einer genauen Teileliste werden Baupläne und Instalationsanleitungen präsentiert. Dies soll den Leser dazu befähigen die Konstruktion vollständig nachbauen zu können. \\
Die komplette Software des Python-Framework findet sich unter \url{https://github.com/Nitzsch/PyBot}. Ebenso wie eine kurze Einführung in die konkrete Nutzung der verschiedenen Module. 

\chapter{Stück- und Preisliste}
In diesem Kapitel findet sich eine vollständige Teileliste. Ebenso sind die einzelnen Bezugsquellen aufgezählt und der Preis. Dieser bezieht sich auf den Privatpersonenkauf ohne jeden Rabatt. Oft wurden 5er Packungen gekauft, da dies den Preis des einzelnen Teils enorm senkt. \\
Nicht aufgezählt sind die Kosten für Lötzinn und Werkzeug. 

\section{Vorhandene Bauteile}
\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		Bezeichnung			&Funktion				& Preis	in Euro	&Bezugsquelle\\
		\hline
		L293D				&Motor-Driver-Chip		& 0.37			& vorhanden		\\
		GD2P12				&Infrarot Distanz-Sensor& 10 (2 Mal)	& vorhanden\\
		LCD-Display			&Anzeige				& 8				& vorhanden	\\
		Opti-Flow-Sensor	&Mouse-Bewegungssensor		& 20			& vorhanden\\
		Motor				& DC-Motor mit Aufhängung& 15			& vorhanden\\
		Gummistopper		& Unterseite			& (3Mal)		& vorhanden \\
		330Ohm Res.			&						& 0(5Mal)		& \\
		2k Ohm Res.			&						& 0(2Mal)		& \\
		5k Ohm Res.			&						& 0				& \\
		\hline
		gesammt:			&						&63.37&\\
		\hline
	\end{tabular}
\end{center}


\section{zugekaufte Sensorik}
\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		Bezeichnung			&Funktion				& Preis	in Euro			&Bezugsquelle\\
		\hline
		MPU6050				&Gyro					& 1.75			& amazon		\\
		ADS1115				&Analog-Digital-Wandler	& 3.50			& amazon		\\
		MCP23017			&I2C-Multiplex			& 0.95			& reichelt		\\
		Ultraschall-		&Distanzsensor			& 1.7 (3Mal)	& amazon		\\
		TCRT5000			&Infrarot-Sensor		& 1.1 (4Mal)	& amazon		\\
		\hline
		gesammt:			&						&15.7			&\\
		\hline			
	\end{tabular}
\end{center}

\section{Raspberry Pi und Zubehör}
\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		Bezeichnung			&Funktion				& Preis	in Euro			&Bezugsquelle\\
		\hline
		Raspberry Pi 		& Version 3B +			& 32.5			& reichelt		\\
		USB-Kabel			& Stromversorgung		& 3.15			& amazon		\\
		SanDisk Speicher	& Micro-SD, 64GB		& 15			& amazon \\
		Powerbank			& 12kmA					& 16			& amazon \\
		Pi-Camera			&Kamera					& 7				& amazon		\\
		Camera Kabel		&Kabel					& 1				& amazon		\\
		\hline
		gesammt:			&						& 74.65				&\\
		\hline
	\end{tabular}
\end{center}

\section{Sonstiges Material}
\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		Bezeichnung			&Funktion				& Preis	in Euro			&Bezugsquelle\\
		\hline
		Button				&						& 0				& 		\\
		LED					&Anzeige				& 0 (2Mal)		&		\\
		Lochrasterplatte	&Sensorboard			& 0.9			& reichelt		\\
		4Pin Leiste			& 						& 0.2 (3 Mal)	& reichelt		\\
		10 Pin Leiste		&						& 0.5			& reichelt		\\
		8 Pin Leiste		&						& 0.4			& reichelt		\\
		24Pin Dop.-Fed.-L.	&						& 0.1			& reichelt		\\
		16Pin Dop.-Fed.-L	&						& 0.1			& reichelt		\\
		40 Pin Header		&						& 0.6			& reichelt		\\
		2Pin PSK-H			&						& 0.1(2Mal)		& reichelt	\\
		2Pin PSK-H (Fem)	&						& 0.1(2Mal)		& reichelt	\\
		3Pin PSK-H			&						& 0.2(3Mal)		& reichelt		\\
		3Pin PSK-H (Fem)	&						& 0.2(3Mal)		& reichelt		\\
		4 Pin PSK-H			&						& 0.2			& reichelt\\
		4 Pin PSK-H	(Fem)	&						& 0.2			& reichelt\\
		20 Pin PSK-H	(Fem)&						& 0.2 (2Mal)	& reichelt\\
		8Pin PSK-H			&						& 0.3(2Mal)		& reichelt\\
		8Pin PSK-H (Fem)	&						& 0.3(2Mal)		& reichelt\\
		Crimp-Kontakte		& 20er Pack				& 0.3 (min 5)	& reichelt\\
		Holzplatte, MDF 4mm	& Radius 7.5cm			& 0.5(3Mal)		& Baumarkt		\\
		M3 Schrauben		& set mit Abstandshalter& 0(40Mal)		& amazon		\\
		M3 Muttern			& set mit Abstandshalter& 0(20Mal)		& amazon		\\
		Kabellitze			& 3 versch. Farben		& 0.76			& reichelt		\\
		Kabelaufhänger		&						& 0.5(3Mal)		& reichelt		\\
		Gummiband			&						& 0				& baumarkt\\
		Abstandshalter 		& Kunststoff, versch. G.& 2				& amazon		\\
		\hline
		gesammt: 			&						&14.06			&\\
		\hline
	\end{tabular}
\end{center}

\section{Gesammtpreis}
\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Bezeichnung				& Preis	in Euro	\\
		\hline
		Sensorik				& 15.7\\
		Raspberry Pi u. Zubehör	& 74.65\\
		sonstige Bauteile:		& 14.06\\
		\hline
		gesammt:				& 104.41\\
		\hline
	\end{tabular}
\end{center}
Viele Preise beziehen sich auf die reduzierten Angebote mit 5 Bauteilen statt einem. D.h. der Preis von 104.41 Euro pro Stück wird nur realisiert, wenn 5 oder mehr gebaut werden. Ansonsten erhöht sich der Preis uU. \\
Muss der Roboter vollständig neu gebaut werden (ohne die Basis des Ct'Bots) so erhöht sich der Preis entsprechend um 63.37 Euro auf 167.78Euro. 

\chapter{Baupläne}
\section{obere Platte}
\includegraphics[angle=90,origin=c, scale= 0.5]{images/Zeichnung_obere_Platte.jpg}
\section{Mittlere Platte}
\includegraphics[angle=90,origin=c, scale= 0.7]{images/Zeichnung_mittlere_Platte.jpg}
\section{Bodenplatte}
\includegraphics[angle=180,origin=c, scale= 0.7]{images/Bodenplatte.pdf}
\section{Akku-Träger}
\includegraphics[angle=90,origin=c, scale= 0.7]{images/Zeichnung_Akku.jpg}
\section{PCB-Layout}
\includegraphics[angle=0,origin=c, scale= 0.75]{images/Layout.png}
\section{PCB-Bestückung}
\includegraphics[angle=90,origin=c, scale= 0.7]{images/PCB-Layout.jpg}

\section{Pin-Belegung}
\subsection{Pinbelegung an der Pi}
Die Pinbelegung orientiert sich an der physischen Verteilung der Pins auf der Pi (BCM-Layout). Vorsicht: Hier wird BCM genutzt, die Python Scripts verwenden jedoch BOARD-Layout. \\
Von 24 frei programmierbaren Pins sind 17 in Benutzung, davon 2 für I2C-Kommunikation. 

\begin{center}
	\begin{tabular}{|cc|c|c|}
		\hline
		Pin 	&BCM		& Function 		& Bauteil\\
		\hline
		2		&3			& I2C - SDA		& ADC , Gyro, MCP23017 (daran LCD, Buttons) \\
		3 		&5			& I2C - SCL		& ADC , Gyro, MCP23017 (daran LCD, Buttons)\\
		4		&7			& Freier Pin	& Ultraschall-Dist-Sens Rechts ECHO\\
		17		&11 		& Freier Pin	& Ultraschall-Dist-Sens Rechts TRIG	\\
		27		&13 		& Freier Pin	& Ultraschall-Dist-Sens Front ECHO	\\
		22		&15 		& Freier Pin	& Ultraschall-Dist-Sens Front TRIG	\\
		10		&19 		& SPI0 - MI		& 	\\
		9		&21 		& SPI0 - MO		& Button		\\
		11		&23 		& SPI0 - CL		& Wheel-Encoder Rechts		\\
		5		&29 		& Freier Pin	& Ultraschall-Dist-Sens Links ECHO		\\
		6		&31 		& Freier Pin	& Ultraschall-Dist-Sens Links TRIG	\\
		13		&33 		& Freier Pin	& Mouse-Sensor Data	\\	
		19		&35 		& Freier Pin	& Mouse-Sensor Clock	\\
		26		&37 		& Freier Pin	& Status LED\\
		14		&8 			& UART - TXD	& 	\\
		15		&10 		& UART - RXD	&  	\\
		18		&12 		& Freier Pin	& 	\\
		23 		&16 		& Freier Pin	& Motor-Chip Pin 15 - Driver-In0 for Mot2	\\
		24		&18 		& Freier Pin	& Motor-Chip Pin 10- Driver-In1 for Mot2	\\
		25		&22 		& Freier Pin	& Motor-Chip Pin 9 - EN for Mot2	\\
		8		&24 		& SPI0 - CE		& 	\\
		7		&26 		& SPI1 - CE		&  	\\
		12		&32 		& Freier Pin	& Wheel-Encoder Links	\\
		16		&36 		& Freier Pin	& Motor-Chip Pin 7 - Driver-In1 for Mot1	\\
		20		&38 		& SPI1 - MO		& Motor-Chip Pin 2 - Driver-In0 for Mot1		\\
		21		&40 		& SPI1	- CL	& Motor-Chip Pin 1 - EN for Mot1	\\
		\hline
	\end{tabular}
\end{center}
\newpage

\subsection{Pinbelegung am MCP}
Die Zählung beginnt am ersten Pin auf der oberen Seite, links. Der erste "freie" Pin ab den Funktions-Pins trägt somit die 1. danach ist die obere Seite belegt bis 8 und dann wird umgehend gezählt. Damit ist der Pin 9 der Pin auf der unteren Seite, ganz rechts und Pin 16 der Pin in der Mitte auf der unteren Seite. 

\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Pin 	& Bauteil\\
		\hline
		1		&  \\
		2 		& \\
		3		& \\
		4		& 	\\
		5		& 	\\
		6		& 	\\
		7		& Cliff-Sensor links\\
		8		& Cliff-Sensor rrechts\\
		9		& LCD D7		\\
		10		& LCD D6 	\\
		11		& LCD D5		\\
		12		& LCD D4	\\
		13		& LCD E	\\	
		14		& LCD RS	\\
		15		& 	\\
		16		& 		\\
		\hline
	\end{tabular}
\end{center}

\subsection{Pinbelegung am AD-Converter}
Pinbelegung wie Aufdruck auf Bauteil, dh. von 0-3, starten ab Mitte.

\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Pin 	& Bauteil\\
		\hline
		0		& 	\\
		1		&  \\
		2 		& IF-Sensor rechts\\
		3		& IF-Sensor links\\
		\hline
	\end{tabular}
\end{center}

\chapter{Installationsanleitung}
Nachdem die Hardware des Roboters fertiggestellt wurde, muss die Software installiert werden. Dies geschieht durch Installation einer Rasbian Version und dem Einrichten dieser, gefolgt von der Installation versch. Python Bibliotheken und dem Framework selbst. 
\section{Raspbian}
Raspbian ist eine speziell für die Raspberry Pi zugeschnittene Linux Variante. Grob baut Sie auf Ubuntu auf und verzichtet auf einige der großen Programme und Treiber, insb. jener für Grafik. \\
Raspbian lässt sich entweder direkt auf einer SD-Karte fertig installiert kaufen oder auf der offiziellen Website\\ \url{https://www.raspberrypi.org/downloads/raspbian/}\footnote{Abgerufen am 01.07.2019 um 14:00 Uhr}
herunterladen. Für ungeübter User empfiehlt sich hierbei die Noobs Version, welche die neueste Raspbian Version einfach zur Verfügung stellt. Für eine genaue Installationsanleitung empfiehlt sich hier das Einsteiger-Forum von Raspbian \url{https://www.raspberrypi.org/documentation/installation/installing-images/README.md}\footnote{Abgerufen am 01.07.2019 um 14:00 Uhr}
.

\subsection{Raspbian einrichten}
Beim grundsätzlichen Einrichten des Betriebssystem sollte man der Einleitung im oben genannten Link folgen. Es sollte aber auf jeden Fall der Nutzername und das zugehörige Passwort geändert werden. Dies kann über die Konsole mit dem Befehl 'raspi-config' geschehen. \\

\subsection{I2C und Kamera}
Es muss die Kamera und der I2C-Kanal aktiviert werden. Dies geschieht im Terminal mit dem Befehl 'sudo raspi-config'. Danach öffnet sich ein Konfigurationsfenster. Hier muss unter der Punkt Interface-Optionen ausgewählt werden. In diesem Unterpunkt findet man die Menüs zu I2C und Kamera. Diese jeweils aktivieren und bestätigen. Die Pi muss danach neu gestartet werden. 

\subsection{VNC-Server}
Danach sollte ein VNC-Server installiert werden um Zugriff auf die Pi zu erhalten. Eine gute Anleitung findet sich auch wieder auf der offiziellen Website der Pi Foundation:\\
\url{https://www.raspberrypi.org/documentation/remote-access/vnc/}\footnote{Abgerufen am 01.07.2019 um 14:00 Uhr}


\subsection{WLan-Access-Point}
Ein WLan-Access-Point erleichtert den Zugriff auf die Pi. Diese stellt fortan ein WLan zur Verfügung auf das jedes externe Gerät zugreifen kann. \\
Eine Anleitung hierzu findet sich erneut auf der offizielen Seite:\\
\url{https://www.raspberrypi.org/documentation/configuration/wireless/access-point.md}\footnote{Abgerufen am 01.07.2019 um 14:00 Uhr}

\subsection{Update and Upgrade}
Vor und nach jeder Installation sollte im Terminal ein Update erzwungen werden. Dies passiert durch den Befehl ' sudo apt-get update' und ' sudo apt-get upgrade'. Ebenso sollte zu Beginn ein großes Update erfolgen durch den Befehl ' sudo apt-get dist-upgrade'. Nach diesen Befehlen empfiehlt sich weiterhin das Kommando ' sudo apt-get autoremove' und 'sudo apt-get autoclean' um veraltete Pakete zu entfernen. 

\section{Python Bibliotheken}

Für die Funktionsfähigkeit des Frameworks werden Python Bibliotheken benötigt, welche nicht in der Standartinstallation enthalten sind. Diese werden im Terminal durch den Befehl 'sudo pip install (BIBLIOTHEKNAME HERE)' installiert.\\
Folgende Pakete werden benötigt: 
\begin{center}
	\begin{itemize}
		\item PIL
		\item CV
		\item numpy
		\item Tkinter
		\item smbus
		\item Adafruit\_ADS1x15
	\end{itemize}
\end{center}
Je nach verwendeter Python Version (2 oder 3) können die Installationsnamen variieren. So heißt PIL für Python2 Pillow und CV ist zu finden unter open-cv oder opencv-python. Sollte die Installation der Pakete scheitern, so empfiehlt es sich hier nachzusehen, wie die Namen für die Installation aufgelöst werden müssen. 

\section{PyBot-Framework}
Das Herzstück der Software ist das Python-Framework. Dieses lässt sich über GitHub auf die eigene Pi clonen. Die Daten findet man unter \url{https://github.com/Nitzsch/PyBot} \footnote{Abgerufen am 02.07.2019 um 15:00 Uhr}\\
Nachdem das Framework heruntergeladen wurde, sollte die Pin-Belegung im Unterordner Drivers an den eigenen Roboter angepasst werden. Danach lässt sich über die Ausführung des Scripts View der Roboter im Nutzer-Interface starten und steuern. \\
Beim Ausprobieren wünscht der Autor viel Spaß und Erfolg. 



\bibliographystyle{alpha}
\bibliography{bibliography}

\end{document}

